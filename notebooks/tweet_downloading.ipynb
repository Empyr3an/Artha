{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd050692dee8d60b45dc70f605c3c7f11300c905f349bdb5557a748ab90862af84a",
   "display_name": "Python 3.7.6 64-bit ('artha@3.7.6': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1356259499431129092 done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import datetime\n",
    "import pickle\n",
    "import inspect\n",
    "import string\n",
    "import collections\n",
    "import numpy as np\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(0,parentdir) \n",
    "\n",
    "import Artha\n",
    "from Artha.twitter import TwitterAPI\n",
    "from Artha.sqlitedb import TSQLite\n",
    "import Artha.configs.twitter_config as c\n",
    "\n",
    "checkra = TwitterAPI(username = \"checkra_\", bearer_token = c.c_bearer, key = c.c_key, secret = c.c_secret, token = c.c_token, token_secret = c.c_token_secret)\n",
    "print(checkra.id,\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': '380546370', 'name': '//Bitcoin ð•µack ðŸ', 'username': 'BTC_JackSparrow'}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "checkra.user_lookup(\"BTC_JackSparrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2721\n"
     ]
    }
   ],
   "source": [
    "tweets = checkra.get_recent_tweets(\"CryptoKaleo\")\n",
    "print(len(tweets))\n",
    "tweet_text = [t[\"full_text\"] for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to get crypto tickers, save into tickers and names lists\n",
    "with open(\"../data/crypto_tickers.json\", \"r\") as w:\n",
    "    tickers = json.loads(w.read())\n",
    "too_common_tickers = [\"ONE\", \"FOR\", \"TRY\", \"WIN\", \"HOT\", \"NEAR\", \"CAN\", \"HARD\", \"BULL\", \"SKY\", \"FUN\", \"EASY\", \"GO\", \"ADD\", \"OG\", \"DATA\", \"ATM\", \"ANT\", \"KEY\"]\n",
    "too_common_names = [\"JUST\", \"HONEST\"]\n",
    "for i in too_common_tickers:\n",
    "    del tickers[i]\n",
    "for i in too_common_names:\n",
    "    for k, v in tickers.items():\n",
    "        if v == i:\n",
    "            del tickers[k]\n",
    "            break\n",
    "coin_ticks = [tick.upper() for tick in tickers.keys()]\n",
    "coin_names = [name.upper() for name in tickers.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods to extract tickers, names, and cashtags for crypto\n",
    "\n",
    "def extract_tickers(sentence):\n",
    "    counts = {}\n",
    "    sen = sentence.translate(str.maketrans('','',string.punctuation)).upper()\n",
    "    sentence_words = sen.split()\n",
    "    tickers = [word for word in sentence_words if word in coin_ticks]\n",
    "\n",
    "    return collections.Counter(tickers)\n",
    "\n",
    "def extract_names(sentence):\n",
    "\n",
    "    sentence = \" \"+sentence.upper()+\" \"\n",
    "    tickers = [coin for coin in coin_names if \" \"+coin+\" \" in sentence]\n",
    "    return collections.Counter(tickers)\n",
    "\n",
    "def extract_cashtags(sentence):\n",
    "    words = sentence.upper().split()\n",
    "    symbols = [word for word in words if len(word) > 1 and word[0]==\"$\" and word[1:].isalpha()]\n",
    "    return collections.Counter(symbols)\n",
    "\n",
    "# extract_general_tickers()\n",
    "test = \"I like BTC and ETH. but link sucks. I like $BTC. Bancor dope\"\n",
    "test2 = \"Largest capitulation on bitcoin futures since March 2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# goes through entire set of recent tweets, extracts tickers\n",
    "final_ticks = []\n",
    "final_names = []\n",
    "final_cash = []\n",
    "with open(\"has.txt\", \"w+\") as w, open(\"not.txt\", \"w+\") as x:\n",
    "    for ind, i in enumerate(tweet_text):\n",
    "        tick = extract_tickers(i)\n",
    "        name = extract_names(i)\n",
    "        cash = extract_cashtags(i)\n",
    "        final_ticks.extend(tick)\n",
    "        final_names.extend(name)\n",
    "        final_cash.extend([c[1:] for c in cash])\n",
    "        if tick or name:\n",
    "            w.write(i+\"\\n\")\n",
    "            json.dump(tick, w)\n",
    "            w.write(\"\\n\")\n",
    "            json.dump(name, w)\n",
    "            w.write(\"\\n\\n\\n\")\n",
    "        else:\n",
    "            x.write(i+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'XRP', 'YFI', 'ETH', 'IOTA', 'SUSHI', 'AVAX', 'SC', 'RUNE', 'NPXS', 'EGLD', 'XLM', 'DOGE', 'BNB', 'SUN', 'NEO', 'CAKE', 'BOT', 'EOS', 'FUEL', 'DOT', 'ALPHA', 'REN', 'FTT', 'BAND', 'BLINK', 'XTZ', 'BTT', 'LTC', 'OMG', 'ENJ', 'FIL', 'GAS', 'TRX', 'LINK', 'USD', 'ZEC', 'SOL', 'PERP', 'SUB', 'DENT', 'SXP', 'CHZ', 'VIA', 'QTUM', 'ADA', 'USDT', 'BAL', '1INCH', 'BTC', 'ETC', 'BAKE', 'STRAX', 'SRM'}\n"
     ]
    }
   ],
   "source": [
    "print(set(final_ticks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'XRP', 'PRAY', 'AAL', 'ETH', 'IOTA', 'NDX', 'OKB', 'BTMX', 'SPY', 'TSLA', 'AVAX', 'SC', 'NPXS', 'EGLD', 'OXY', 'XLM', 'DOGE', 'BNB', 'NEO', 'CAKE', 'RDD', 'EOS', 'PENN', 'HOT', 'DJI', 'FTT', 'BAND', 'XTZ', 'BTT', 'LTC', 'FTTCONTINUIJNG', 'OMG', 'ENJ', 'FIL', 'KIN', 'TRX', 'LINK', 'ZEC', 'SOL', 'DENT', 'COIN', 'SXP', 'QQQ', 'UAL', 'QTUM', 'ADA', 'BAL', 'BTC', 'ETC', 'STRAX', 'SRM', 'VIAC'}\n"
     ]
    }
   ],
   "source": [
    "print(set(final_cash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['1INCH', 'ALPHA', 'BAKE', 'BLINK', 'BOT', 'CHZ', 'DOT', 'FUEL',\n",
       "       'GAS', 'PERP', 'REN', 'RUNE', 'SUB', 'SUN', 'SUSHI', 'USD', 'USDT',\n",
       "       'VIA', 'YFI'], dtype='<U5')"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "np.setdiff1d(list(set(final_ticks)), list(set(final_cash)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['AAL', 'BTMX', 'COIN', 'DJI', 'FTTCONTINUIJNG', 'HOT', 'KIN',\n",
       "       'NDX', 'OKB', 'OXY', 'PENN', 'PRAY', 'QQQ', 'RDD', 'SPY', 'TSLA',\n",
       "       'UAL', 'VIAC'], dtype='<U14')"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "np.setdiff1d(list(set(final_cash)), list(set(final_ticks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get better at extracting tickers from tweets\n",
    "# TODO Download recent tweets for all people I follow"
   ]
  }
 ]
}