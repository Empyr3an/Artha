{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0336ff5ee2c1e0e67b5ec251f9bb85714e66dde2cea2c3ccd73e788234e60283a",
   "display_name": "Python 3.7.6 64-bit ('artha@3.7.6')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.66 s, sys: 259 ms, total: 1.92 s\nWall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "import inspect\n",
    "import tqdm\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(0,parentdir) \n",
    "\n",
    "import Artha\n",
    "from Artha.analysis import *\n",
    "from Artha.nlp_extraction import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 62.7 ms, sys: 12.3 ms, total: 75 ms\nWall time: 74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# user = \"naval\"\n",
    "user = \"CryptoKaleo\"\n",
    "with open(\"../data/tweets/u\"+user+\"tweets.json\", \"r\") as r:\n",
    "    tweets = json.load(r)\n",
    "tweet_text = []\n",
    "for ind, tweet in enumerate(tweets):\n",
    "    sent = tweet[\"full_text\"]\n",
    "    \n",
    "    try: #remove tweets of only tagging someone\n",
    "        while sent[0] == \"@\":\n",
    "            sent = sent.split(\" \", 1)[1]\n",
    "        tweet_text.append(sent.replace(\"&amp;\", \"and\").replace(\"@\", \"\"))\n",
    "    except:\n",
    "        tweets.pop(ind)\n",
    "# tweet_text = [tweet[\"full_text\"] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.96 s, sys: 122 ms, total: 2.08 s\nWall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spacy_sents = []\n",
    "# need to disable pipes\n",
    "with open(\"senti2.txt\", \"w+\") as w:\n",
    "    for ind, doc in enumerate(nlp.pipe(tweet_text, n_process=-1)):\n",
    "        # tick = [ent.text for ent in doc.ents if ent.label_ in ent_labels]\n",
    "        # labels = [ent.label_ for ent in doc.ents if ent.label_ in ent_labels]\n",
    "        tick = doc._.tickers\n",
    "        for i in tick:\n",
    "            if i not in tickers.keys() and i not in tickers.values():\n",
    "                tick.remove(i)\n",
    "        if tick: # \n",
    "            w.write(\" \".join(tick)+\"\\n\")\n",
    "            w.write(str(ind)+\" \"+doc.text+\"\\n\\n\")\n",
    "            spacy_sents.append(ind)\n",
    "        \n",
    "        #     if abs(doc._.polarity)>0:\n",
    "        #         w.write(\" \".join(tick)+\"\\n\")\n",
    "        #         w.write(\" \".join(labels)+\"\\n\")\n",
    "        #         # w.write(\"\\n\")\n",
    "        #         # w.write(str(doc._.polarity)+\" \"+str(doc._.subjectivity)+\"\\n\")\n",
    "        #         # vs = analyzer.polarity_scores(sent)\n",
    "        #         # w.write(\"{:-<65} {}\\n\\n\".format(str(ind)+\" \"+sent, str(vs)))\n",
    "        #         w.write(str(ind)+\" \"+doc.text+\"\\n\\n\")\n",
    "        # if not tick:\n",
    "        #     w.write(str(ind)+\" \"+doc.text+\"\\n\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bitcoin is $1,000 lower than it was yesterday at this time, and alts are all printing higher highs across the board led by Ethereum.\n\nThis is the moment we've been waiting for.\n\nSalt szn is over. Alt szn is here. \n\nBitcoin\n1,000\nNot in \n\nEthereum\n\n\nBitcoin ORG\n1,000 MONEY\nyesterday DATE\nEthereum ORG\nSalt PERSON\n\n ['Bitcoin', '1,000', 'Ethereum']\nCPU times: user 16.9 ms, sys: 2.34 ms, total: 19.3 ms\nWall time: 18.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ent_labels = [\"CRYPTO\", \"ORG\", \"MONEY\"]\n",
    "\n",
    "doc = nlp(tweet_text[28])\n",
    "print(doc.text, \"\\n\")\n",
    "tick = [ent.text for ent in doc.ents if ent.label_ in ent_labels]\n",
    "for i in tick:\n",
    "    print(i)\n",
    "    if i not in tickers.keys() and i not in tickers.values():\n",
    "#         tick.remove(i)\n",
    "        print(\"Not in\",\"\\n\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "#     if i not in tickers.keys() or tickers.values():\n",
    "#         tick.remove(i)\n",
    "for ent in doc.ents:\n",
    "    # if ent.label_ == \"ORG\" or ent.label_ == \"CRYPTO\":\n",
    "        # if i in tickers.keys() or tickers.values()\n",
    "        # print(ent.text, ent.label_)\n",
    "    print(ent.text, ent.label_)\n",
    "print(\"\\n\", tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['BTC', 'KIN']\nKIN ORG\nBTC ORG\nATH ORG\n5 CARDINAL\n1 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(tweet_text[1634])\n",
    "# doc_ents = [ent.text for ent in doc.ents if ent.label_ in ent_labels]\n",
    "print(sorted(doc._.tickers))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}