{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0336ff5ee2c1e0e67b5ec251f9bb85714e66dde2cea2c3ccd73e788234e60283a",
   "display_name": "Python 3.7.6 64-bit ('artha@3.7.6')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "import inspect\n",
    "import tqdm\n",
    "import contractions\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(0,parentdir) \n",
    "\n",
    "import Artha\n",
    "from Artha.analysis import *\n",
    "from Artha.nlp_extraction import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "user = \"Nostranomist\"\n",
    "# user = \"CryptoKaleo\"\n",
    "with open(\"../data/tweets/u\"+user+\"tweets.json\", \"r\") as r:\n",
    "    tweets = json.load(r)\n",
    "tweet_text = []\n",
    "for ind, tweet in enumerate(tweets):\n",
    "    sent = tweet[\"full_text\"]\n",
    "    \n",
    "    try: #remove tweets of only tagging someone\n",
    "        while sent[0] == \"@\":\n",
    "            sent = sent.split(\" \", 1)[1]\n",
    "        tweet_text.append(contractions.fix(sent.replace(\"&amp;\", \"and\").replace(\"@\", \"\")))\n",
    "    except:\n",
    "        tweets.pop(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# need to disable pipes\n",
    "with open(\"senti.txt\", \"w+\") as w:\n",
    "    for ind, doc in enumerate(nlp.pipe(tweet_text, n_process=-1)):\n",
    "        tick = doc._.tickers\n",
    "                \n",
    "        if tick:\n",
    "            w.write(\"***\"+str(ind)+\" \"+\" \".join(tick)+\"***\"+str(doc._.polarity)+\" \"+str(doc._.subjectivity)+\"\\n\")\n",
    "            w.write(doc.text+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(tweet_text[1883])\n",
    "print(sorted(doc._.tickers))\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  }
 ]
}